##### start of the Pipeline #####
## The input is the fastq files from the sequencer ##
## the goal is to concatenate files together, trim the adapter sequences, and align with BWA 

##### Step 1: concatenate fastq files so each sample has 1 forward and 1 reverse read #####
# SeqID.txt contains the unique identifier at teh beginning of each file name, one to a line

# start by combining 001 to 00X for each lane independently
# run these lines in the directory with 
while IFS= read -r line; do for x in 1 2; do cat "$line"_L00"$x"_R1_00*.fastq > "$line"_L00"$x"_R1_comb.fastq; done; done < SeqID.txt
while IFS= read -r line; do for x in 1 2; do cat "$line"_L00"$x"_R2_00*.fastq > "$line"_L00"$x"_R2_comb.fastq; done; done < SeqID.txt
# now join the L001 and L002 together
while IFS= read -r line; do cat "$line"_L001_R1_comb.fastq "$line"_L002_R1_comb.fastq > "$line"_R1_comb.fastq; done < SeqID.txt
while IFS= read -r line; do cat "$line"_L001_R2_comb.fastq "$line"_L002_R2_comb.fastq > "$line"_R2_comb.fastq; done < SeqID.txt
# and remove the intermediate files for space
rm *_L00*_R*_comb.fastq
# bgzip everyting for space
cd /mnt/research/RadishSequence/ArabidopsisSequence/fastq
for f in *.fastq; do ~/Apps/bgzip "$f";done

##### Step 2: Run FastQC to check sample quality #####
ssh -X buysseso@hpcc.msu.edu
ssh dev-amd20-v100
# module load GCC/7.3.0-2.30  OpenMPI/3.1.1
# module load FastQC
# module load MultiQC/1.7-Python-3.6.6

# https://multiqc.info/docs/#running-multiqc
# choosing to just do it on the forward reads
while IFS= read -r line; do fastqc /mnt/research/RadishSequence/ArabidopsisSequence/fastq/"$line"_R1_comb.fastq & done < SeqID.txt
multiqc . # to generate a single report form all the reports in the current directory

#### Step 3: Trim Adapter Sequences #####
### 2A do this with trimmomatic ###

#!/bin/bash
##Job settings for without -t settings
#SBATCH --job-name=test_trimmomatic
#SBATCH -e test_trimmomatic.err
#SBATCH -o test_trimmomatic.out

##Job Resources
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=6gb
#SBATCH -t 23:59:00
#SBATCH --mail-user=buysseso@msu.edu
#SBATCH --mail-type=FAIL,BEGIN,END

cd $SLURM_SUBMIT_DIR

###############
## VARIABLES ##
###############

module load Java/11.0.2 \
Trimmomatic/0.39-Java-11

while IFS= read -r line; do java -jar $EBROOTTRIMMOMATIC/trimmomatic-0.39.jar \
 PE \
-phred33 \
-basein /mnt/research/RadishSequence/ArabidopsisSequence/fastq/"$line"_R1_comb.fastq.gz \
-baseout /mnt/research/RadishSequence/ArabidopsisSequence/fastq/trimmed/"$line".fastq.gz \
ILLUMINACLIP:/mnt/research/RadishSequence/ArabidopsisSequence/fastq/Nextera_adapter.fa:2:30:10 \
LEADING:3 \
TRAILING:3 \
SLIDINGWINDOW:4:15 \
MINLEN:30; done < /mnt/research/RadishSequence/ArabidopsisSequence/fasq/SeqID.txt

# then fastqc these
# module load GCC/7.3.0-2.30  OpenMPI/3.1.1
# module load FastQC
# module load MultiQC/1.7-Python-3.6.6
while IFS= read -r line; do fastqc /mnt/research/RadishSequence/ArabidopsisSequence/fastq/trimmed/"$line"_1P.fastq & done < /mnt/research/RadishSequence/ArabidopsisSequence/fastq/SeqID.txt
multiqc ~/mnt/research/RadishSequence/ArabidopsisSequence/fastq/trimmed

### 2B: do this with Trim Galore ###
# this trims and then runs fastq again on the trimmed file all at once!
# https://github.com/FelixKrueger/TrimGalore/blob/master/Docs/Trim_Galore_User_Guide.md

#!/bin/bash
##Job settings for without -t settings
#SBATCH --job-name=test_trimgalore
#SBATCH -e test_trimgalore.err
#SBATCH -o test_trimgalore.out

##Job Resources
#SBATCH --nodes=4
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=2
#SBATCH --mem-per-cpu=6gb
#SBATCH -t 23:59:00
#SBATCH --mail-user=buysseso@msu.edu
#SBATCH --mail-type=FAIL,BEGIN,END

cd $SLURM_SUBMIT_DIR

###############
## VARIABLES ##
###############
module load GCC/7.3.0-2.30  OpenMPI/3.1.1 TrimGalore/0.6.5
while IFS= read -r line; do trim_galore \
--cores 4 \
--nextera \
--paired \
--hardtrim3 10 \
--quality 20 \
--fastqc \
-o /mnt/scratch/buysseso/TG_trimmed "$line"_R1_comb.fastq.gz "$line"_R2_comb.fastq.gz; done < /mnt/research/RadishSequence/ArabidopsisSequence/fastq/SeqID.txt 

# Submitted batch job 32000594

#### Step 4: Align to Reference Genome
#!/bin/bash
##Job settings for without -t settings
#SBATCH --job-name=BWA
#SBATCH -e BWA.err
#SBATCH -o BWA.out

##Job Resources
#SBATCH --nodes=4
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=2
#SBATCH --mem-per-cpu=6gb
#SBATCH -t 23:59:00
#SBATCH --mail-user=buysseso@msu.edu
#SBATCH --mail-type=FAIL,BEGIN,END

cd $SLURM_SUBMIT_DIR

##### code lines #####
module purge

module load GCC/7.3.0-2.30  OpenMPI/3.1.1
module load SAMtools
module load BWA
module load GATK/4.1.4.1-Python-3.6.6

bwa index /mnt/research/RadishSequence/ArabidopsisSequence/refChromFiles/Athal.fasta /mnt/research/RadishSequence/ArabidopsisSeuqence/refChromFiles/Athal
cd /mnt/scratch/buysseso/TG_trimmed

while IFS= read -r line; do bwa mem -t 4 /mnt/research/RadishSequence/ArabidopsisSequence/refChromFiles/Athal.fasta \
"$line"_R1_comb_val_1.fq.gz  "$line"_R2_comb_val_2.fq.gz \
| samtools view - -bS -o /mnt/scratch/buysseso/BWA_bam/"$line"_bwa.bam; done < /mnt/research/RadishSequence/ArabidopsisSequence/fastq/SeqID.txt

cd /mnt/scratch/buysseso/BWA_bam

while IFS= read -r line; do
samtools sort "$line"_bwa.bam -o sorted_"$line"_bwa.bam
samtools index sorted_"$line"_bwa.bam
samtools view sorted_"$line"_bwa.bam | less -S
samtools flagstat sorted_"$line"_bwa.bam > "$line"_alignment_metrics.txt; done < /mnt/research/RadishSequence/ArabidopsisSequence/fastq/SeqID.txt

#Submitted batch job 32657542
# ran line 147 to end separately as samtools_stats.sb > Submitted batch job 33233713

