##### start of the Pipeline #####
## The input is the fastq files from the sequencer ##
## the goal is to concatenate files together, trim the adapter sequences, and align with BWA 

##### Step 1: concatenate fastq files so each sample has 1 forward and 1 reverse read #####
# SeqID.txt contains the unique identifier at the beginning of each file name, one to a line

# start by combining 001 to 00X for each lane independently
# run these lines in the directory with 
while IFS= read -r line; do for x in 1 2; do cat "$line"_L00"$x"_R1_00*.fastq > "$line"_L00"$x"_R1_comb.fastq; done; done < SeqID.txt
while IFS= read -r line; do for x in 1 2; do cat "$line"_L00"$x"_R2_00*.fastq > "$line"_L00"$x"_R2_comb.fastq; done; done < SeqID.txt
# now join the L001 and L002 together
while IFS= read -r line; do cat "$line"_L001_R1_comb.fastq "$line"_L002_R1_comb.fastq > "$line"_R1_comb.fastq; done < SeqID.txt
while IFS= read -r line; do cat "$line"_L001_R2_comb.fastq "$line"_L002_R2_comb.fastq > "$line"_R2_comb.fastq; done < SeqID.txt
# and remove the intermediate files for space
rm *_L00*_R*_comb.fastq
# bgzip everyting for space
cd /mnt/research/RadishSequence/ArabidopsisSequence/fastq
for f in *.fastq; do ~/Apps/bgzip "$f";done

##### Step 2: Run FastQC to check sample quality #####
ssh -X buysseso@hpcc.msu.edu
ssh dev-amd20-v100
# module load GCC/7.3.0-2.30  OpenMPI/3.1.1
# module load FastQC
# module load MultiQC/1.7-Python-3.6.6

# https://multiqc.info/docs/#running-multiqc
# choosing to just do it on the forward reads
while IFS= read -r line; do fastqc /mnt/research/RadishSequence/ArabidopsisSequence/fastq/"$line"_R1_comb.fastq & done < SeqID.txt
multiqc . # to generate a single report form all the reports in the current directory

#### Step 3: Trim Adapter Sequences #####
### 2A do this with trimmomatic ###

#!/bin/bash
##Job settings for without -t settings
#SBATCH --job-name=test_trimmomatic
#SBATCH -e test_trimmomatic.err
#SBATCH -o test_trimmomatic.out

##Job Resources
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=6gb
#SBATCH -t 23:59:00
#SBATCH --mail-user=buysseso@msu.edu
#SBATCH --mail-type=FAIL,BEGIN,END

cd $SLURM_SUBMIT_DIR

###############
## VARIABLES ##
###############

module load Java/11.0.2 \
Trimmomatic/0.39-Java-11

while IFS= read -r line; do java -jar $EBROOTTRIMMOMATIC/trimmomatic-0.39.jar \
 PE \
-phred33 \
-basein /mnt/research/RadishSequence/ArabidopsisSequence/fastq/"$line"_R1_comb.fastq.gz \
-baseout /mnt/research/RadishSequence/ArabidopsisSequence/fastq/trimmed/"$line".fastq.gz \
ILLUMINACLIP:/mnt/research/RadishSequence/ArabidopsisSequence/fastq/Nextera_adapter.fa:2:30:10 \
LEADING:3 \
TRAILING:3 \ # this line cuts off low quality reads at the end which trim galore doesn't do... can I have trim galore do this?
SLIDINGWINDOW:4:15 \
MINLEN:30; done < /mnt/research/RadishSequence/ArabidopsisSequence/fasq/SeqID.txt

# then fastqc these
# module load GCC/7.3.0-2.30  OpenMPI/3.1.1
# module load FastQC
# module load MultiQC/1.7-Python-3.6.6
while IFS= read -r line; do fastqc /mnt/research/RadishSequence/ArabidopsisSequence/fastq/trimmed/"$line"_1P.fastq & done < /mnt/research/RadishSequence/ArabidopsisSequence/fastq/SeqID.txt
multiqc ~/mnt/research/RadishSequence/ArabidopsisSequence/fastq/trimmed

### 2B: do this with Trim Galore ###
## updated 2/10/2022
# this trims and then runs fastq again on the trimmed file all at once!
# https://github.com/FelixKrueger/TrimGalore/blob/master/Docs/Trim_Galore_User_Guide.md

#!/bin/bash
#SBATCH --job-name=TG_2
#SBATCH -e tg.err
##Job Resources
#SBATCH --nodes=4
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=2
#SBATCH --mem-per-cpu=6gb
#SBATCH -t 23:59:00
#SBATCH --mail-user=buysseso@msu.edu
#SBATCH --mail-type=FAIL,BEGIN,END

cd $SLURM_SUBMIT_DIR

###############
## VARIABLES ##
###############
module load GCC/7.3.0-2.30  OpenMPI/3.1.1 TrimGalore/0.6.5
while IFS= read -r line; do trim_galore \
--cores 4 \
--nextera \
--paired \
--clip_R1 15 \
--clip_R2 15 \
--quality 20 \
--fastqc \
-o /mnt/scratch/buysseso/TG_trimmed "$line"_R1_comb.fastq.gz "$line"_R2_comb.fastq.gz; done < /mnt/research/josephslab/Sophie/Athal_2/SeqID.txt 

# Submitted batch job 45450169 
# code at /mnt/research/josephslab/Sophie/Athal_2/TrimGal.sb

#### Step 4: Align to Reference Genome
#!/bin/bash
#SBATCH --job-name=BWA_2
#SBATCH -e BWA2.err
#SBATCH -o BWA2.out

##Job Resources
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=2
#SBATCH --mem-per-cpu=6gb
#SBATCH -t 50:59:00
#SBATCH --mail-user=buysseso@msu.edu
#SBATCH --mail-type=FAIL,BEGIN,END

cd $SLURM_SUBMIT_DIR

##### code lines #####
module purge
module load GCC/7.3.0-2.30  OpenMPI/3.1.1
module load SAMtools
module load BWA
module load GATK/4.1.4.1-Python-3.6.6

bwa index /mnt/research/josephslab/Sophie/Athal_2/refChromFiles/Athal.fasta /mnt/research/josephslab/Sophie/Athal_2/refChromFiles/Athal
cd /mnt/scratch/buysseso/TG_trimmed

while IFS= read -r line; do bwa mem -t 4 -M /mnt/research/josephslab/Sophie/Athal_2/refChromFiles/Athal.fasta \
"$line"_R1_comb_val_1.fq.gz  "$line"_R2_comb_val_2.fq.gz \
| samtools view - -bS -o /mnt/scratch/buysseso/BWA_bam/"$line"_bwa.bam; done < /mnt/research/josephslab/Sophie/Athal_2/SeqID.txt

cd /mnt/scratch/buysseso/BWA_bam

while IFS= read -r line; do
samtools sort "$line"_bwa.bam -o sorted_"$line"_bwa.bam
samtools index sorted_"$line"_bwa.bam
samtools view sorted_"$line"_bwa.bam | less -S
samtools flagstat sorted_"$line"_bwa.bam > "$line"_alignment_metrics.txt; done < /mnt/research/josephslab/Sophie/Athal_2/SeqID.txt

# code updated 2/10/2022
# submitted 2/11/2022 as job 45499831
# timed out but it seriously was so close to the end. Most already had an alignment metrics file when it timed out
# ran as a separate job, finished 2/15/2022

## actually maybe everything was never done?
## code to redo some of the bwa mem and alignment
## saved this as BWA3.sb

while IFS= read -r line; do bwa mem -t 4 -M /mnt/research/josephslab/Sophie/Athal_2/refChromFiles/Athal \
"$line"_R1_comb_val_1.fq.gz  "$line"_R2_comb_val_2.fq.gz \
| samtools view - -bS -o /mnt/scratch/buysseso/BWA_bam/"$line"_bwa.bam; done < /mnt/research/josephslab/Sophie/Athal_2/SeqID.txt

bwa mem -t 4 -M /mnt/research/josephslab/Sophie/Athal_2/refChromFiles/Athal \
Vie-6_AGGCAGAA-AAGGAGTA_R1_comb_val_1.fq.gz  "Vie-6_AGGCAGAA-AAGGAGTA_R2_comb_val_2.fq.gz \
| samtools view - -bS -o /mnt/scratch/buysseso/BWA_bam/Vie-6_AGGCAGAA-AAGGAGTA_bwa_tmp.bam

samtools sort Vie-6_AGGCAGAA-AAGGAGTA_bwa_tmp.bam -o sorted_Vie-6_AGGCAGAA-AAGGAGTA_bwa_tmp.bam
samtools index sorted_Vie-6_AGGCAGAA-AAGGAGTA_bwa_tmp.bam
samtools view sorted_Vie-6_AGGCAGAA-AAGGAGTA_bwa_tmp.bam | less -S
samtools flagstat sorted_Vie-6_AGGCAGAA-AAGGAGTA_bwa_tmp.bam > Vie-6_AGGCAGAA-AAGGAGTA_tmp_alignment_metrics.txt

#### needed like 80 hours

# test calculating coverage at this point in time
module purge
module load GCC/11.3.0 BamTools/2.5.2
bamtools coverage -in ALE10_TCCTGAGC-CTCTCTAT_bwa.bam -out ALE10_bwa_coverage.txt
# error. data not sorted correctly. ok! not this one.

bamtools coverage -in sorted_ALE10_TCCTGAGC-CTCTCTAT_bwa.bam -out ALE10_sorted_coverage.txt
# this is taking like 30 minutes to run for a single sample. 

bamtools coverage -in ALE10_TCCTGAGC-CTCTCTAT_rg.bam -out ALE10_rg_coverage.txt
bamtools coverage -in ALE10_TCCTGAGC-CTCTCTAT_rg_rmdup.bam -out ALE10_rmdup_coverage.txt

ALE10_TCCTGAGC-CTCTCTAT_bwa.bam
ALE10_TCCTGAGC-CTCTCTAT_rg.bam
ALE10_TCCTGAGC-CTCTCTAT_rg_rmdup.bam - indexed
sorted_ALE10_TCCTGAGC-CTCTCTAT_bwa.bam - indexed


