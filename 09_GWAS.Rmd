---
title: "GWAS"
author: "Sophie Buysse"
date: '2022-08-09'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Code to run GWAS with Gemma and make the output.

# Step 1: create fam file. 
You can do this with R. This is also where you will want to do any transformations.

### Prep ###

Load packages,  read in the data, do some formatting, and calculate raw line means.
```{r, warning = FALSE}
## load packages 
library(emmeans)
library(lme4)
library(dplyr)
library(rcompanion) ## for plotNormalHistogram and blom functions (really don't need anymore if use hist() function)
library(MASS) ## for boxcox transformation
library(bestNormalize)


## load data
Sequenced <- read.csv("data/SpanishMasterDataset_Sequenced.csv")
PopMetaData <- read.csv("data/SpanishMasterDataset_PopMetaData.csv")

## format columns as factors
Sequenced <- Sequenced[,1:9]
Sequenced$SeqSampleID <- as.factor(Sequenced$SeqSampleID)
Sequenced$Population <- as.factor(Sequenced$Population)
Sequenced$Line <- as.factor(Sequenced$Line)
Sequenced$Rep <- as.factor(toupper(Sequenced$Rep))
# Plant is equivalent to Rep 
Sequenced$Tube <- as.factor(Sequenced$Tube)
str(Sequenced)

## calculate raw means
Seq_RawMeans <- Sequenced %>% group_by(SeqSampleID) %>%
  summarize(Seq_LineFlwrMean = mean(Short_Stamens))

# only keep some of the metadata that will be important later on
PopMetaData <- PopMetaData[, c("PopCode", "Elev_m")]
```

### Line LSMs ###
Set up some stuff to check if I should use raw means or least squared means.
 
Now summarize by Line for the sequenced plants only because the purpose of these means is for GWAS.

```{r}
# LSMs
## create a fully nested random model
colnames(Sequenced)
# the important ones are
# Population
# line
# Rep
# Tube
# this doesn't include the flower b/c we want a mean

# mixed model
S_m2 <- lmer(Short_Stamens ~ SeqSampleID + (1|Rep:Line:Population) + (1|Tube:Rep:Line:Population), 
         data = Sequenced)
summary(S_m2)

anova(S_m2)

Seq_LSM <- summary(emmeans(S_m2, spec = "SeqSampleID"))

# compare values
Comp <- merge(Seq_RawMeans, Seq_LSM, by = "SeqSampleID")

# let's see a correlations
cor.test(Comp$Seq_LineFlwrMean, Comp$emmean)
# so highly correlated. Let's make a plot just to visualize that
# r = 0.9992486 p = <2.2e-16
plot(Comp$Seq_LineFlwrMean ~ Comp$emmean)
lines(x = c(0,1,2), y = c(0,1,2))
```

based on these results, I should use the raw means when I think about transformations.

### Transformations ###
Set up for transformations.
```{r transform}
# to do transformations, I care about the distribution of the means, not which line they belong to
raw_means <- Seq_RawMeans$Seq_LineFlwrMean
plotNormalHistogram(raw_means)
shapiro.test(raw_means)
# w=0.85331, p = 3.273-06

# can same shapiro wilk test results and put into a data frame to make a comparison

# best normalize package
# tests Yeo-Johnson, Box Cox, log10(x+a), sqrt(x+a), and arcsinh
# a = max(0, -min(x)+eps)
# can use new_transform argument to give best Normalise a list of functions to also use (I think this is basically what I am doing by hand below??)
bestNormalize(raw_means, standardize = FALSE, warm = TRUE)
# best is the lowest value. Ordernorm transform is the best but I don't want that, then yeo-johnson, exp, boxcox
#sqrt(x + a) isn't great but is the same value as arcsinh(x)

# squared
means_squared <- raw_means^2
# square root
means_sqrt <- sqrt(raw_means)
# cubic root
means_cubrt <- (raw_means)^(1/3)
# log10
means_log10 <- log10(raw_means)
# natural log
means_log <- log(raw_means)
#inverse
means_inv <- (raw_means)^(-1)
# exponential
means_exp <- exp(raw_means)
# asin_proportion
# doesn't work on values greater than 1 b/c is for proportions
means_asin <- asin(raw_means/2)
# asin_prop_sqrt
# some sources (https://www.programmingr.com/tutorial/arcsine-transformation/) describe the arcsine transformation as needing to be arcsine of the square root
means_asin_sqrt <- asin(sqrt(raw_means/2))
# tukey
means_tukey <- transformTukey(raw_means)
# boxcox
bc <- bestNormalize::boxcox(raw_means)
box <- MASS::boxcox(raw_means ~ 1, lambda = seq(-5,5,0.1))
cox <- data.frame(box$x, box$y)
cox2 <- cox[with(cox, order(-cox$box.y)),]
cox2[1,]
lambda <- cox2[1, "box.x"]

means_bc_bn <- predict(bc)
means_bc_MASS <- ((raw_means^lambda)-1)/lambda

# rank (don't want to use this one b/c it forces a normal distribution)
means_qqnorm <- qqnorm(raw_means, plot = F)
means_rank <- means_qqnorm[["x"]]

# blom - is a rank based method
means_blom <- blom(raw_means, method = "blom", alpha = 3/8, complete = T, na.last = NA)

###### make a list of my new phenotype lists #####
transformations <- list("raw" = raw_means, "squared" = means_squared, "sqrt" = means_sqrt, "Cube rt" = means_cubrt, "Log 10" = means_log10, "Natural Log" = means_log, "inverse" = means_inv, "exponential" = means_exp, "Asin of Proportion" = means_asin, "Asin of Sqrt(proportion)" = means_asin_sqrt, "Tukey" = means_tukey, "BoxCox (BestNormalize)" = means_bc_bn, "BoxCox (MASS)" = means_bc_MASS, "Rank" = means_rank, "Blom" = means_blom)

## make plots of everything
for (i in 1:length(transformations)){
  plotNormalHistogram(transformations[[i]], main = names(transformations)[i])
}

## and do shapiro wilks tests
SW_test <- lapply(transformations, shapiro.test)
# make dummy vector
SW_pval <- rep(NA, times = length(SW_test))
for (i in 1:length(SW_test)){
  SW_pval[[i]] <- SW_test[[i]]$p.value
}
best_transformations <- data.frame("function" = names(transformations), "p.value" = SW_pval)
best_transformations[order(best_transformations$p.value, decreasing = TRUE), ]
# reminder: for a shapiro-wilks test, we are testing for normality. This means that a p value less than 0.05 means you reject the hypothesis that the data is normal, so we are looking for higher values to indicate a more normal dataset.

# or 
norm.compare <- data.frame(names = names(SW_test), stat = names(SW_test), p.val = names(SW_test))
for (i in 1:length(transformations)) {
  norm.compare$names[i] <- names(SW_test)[i] # if correct this shouldn't change anything
  norm.compare$stat[i] <- SW_test[[i]][["statistic"]]
  norm.compare$p.val[i] <- SW_test[[i]][["p.value"]]
}

# order of best to worst in terms of normality
norm.compare[(order(norm.compare$stat, decreasing = TRUE)), ]
```
Order of Phenotype transformations, most normal to least normal:
1. Rank - made phenos file
2. Blom
3. Asin of SQRT(proportion) - made phenos file
4. Asin of proportion
5. exponential
6. Tukey
7. BoxCox calculated by MASS
8. squared
9. BoxCox calculated by Best Normalize
10. Raw phenotypes - made phenos file
11. Square Root
12. Cube root
13. Log 10
14. Natural Log
15. Inverse

Well this support that arcsine is the best!

Nothing besides rank actually passes a normality test, so I definitely don't solve the problem. Not surprising that Rank and blom are the best. 

Untransformed isn't the worse!

### Binary Phenotype ###

Here I want to create a file that has stamen loss coded as binary, so either loss or no loss.
```{r}
hist(Seq_RawMeans$Seq_LineFlwrMean, breaks = 30)

no_2 <- Seq_RawMeans[Seq_RawMeans$Seq_LineFlwrMean < 2, ]
hist(no_2$Seq_LineFlwrMean)

no_close <- Seq_RawMeans[Seq_RawMeans$Seq_LineFlwrMean < 1.62, ]
hist(no_close$Seq_LineFlwrMean)
# ok totally still not normal.

Seq_RawMeans$Binary <- c(rep(0, times = 61))

# choosing strict definition of trait loss
Seq_RawMeans$Binary[Seq_RawMeans$Seq_LineFlwrMean < 2] = 1
# zero indicates no short stamen loss (control), one indicates that there is short stamen loss (case).

## gemma says to use 0 for control and 1 for case for binary. 

```

### Create file to merge with genetic data ###
So let's make a fam file or a phenotype file that plink can read.
```{r}
# make a fam file from scratch
# column 1 (fam) and 2 (id) are sequence ID, column 3 (pat),4 (mat),5 (sex) are all zeros, column 6 (pheno) is the phenotype

# to use the --phenos call in plink, I need 3 columns: FID, IID, pheno

new_fam <- data.frame("FID" = as.character(Seq_RawMeans$SeqSampleID), "IID" = as.character(Seq_RawMeans$SeqSampleID), "pheno" = Seq_RawMeans$Seq_LineFlwrMean)
# manually updated Pal-12 to PAL12 on all because the vcf has PAL12
new_fam$FID[new_fam$FID == "Pal-12"] <- "PAL12"
new_fam$IID[new_fam$IID == "Pal-12"] <- "PAL12"

# raw phenotypes
write.table(new_fam, file = "~/FamFiles/RawLineMeans_08092022.txt", quote = FALSE, sep = " ", col.names = FALSE, row.names = FALSE)

# rank phenotypes
new_fam$rank <- means_rank
new_fam$pheno <- NULL
colnames(new_fam) <- c("FID", "IID", "pheno")
write.table(new_fam, file = "~/FamFiles/RankLineMeans_08152022.txt", quote = FALSE, sep = " ", col.names = FALSE, row.names = FALSE)

# arcsin of sqrt of a proportion
new_fam$asin <- means_asin_sqrt
new_fam$pheno <- NULL
colnames(new_fam) <- c("FID", "IID", "pheno")
write.table(new_fam, file = "~/FamFiles/AsinSqrtPropLineMeans_08152022.txt", quote = FALSE, sep = " ", col.names = FALSE, row.names = FALSE)

# binary phenotype - strict definition
## gemma says to use 0 for and 1 for 
new_fam$binary <- Seq_RawMeans$Binary
new_fam$pheno <- NULL
colnames(new_fam) <- c("FID", "IID", "pheno")
write.table(new_fam, file = "~/FamFiles/BinaryPhenotype_01102023.txt", quote = FALSE, sep = " ", col.names = FALSE, row.names = FALSE)
```

Super important note! This fam file is organized in alphabetical order. 

Move this file onto the HPCC. 

The order was actually not important when using the --pheno tag in plink because it matches up by ID instead of row order.

```{r}
# addition on 2/20/2024
# I need to calculate shapiro wilks for the subset distribution
# reading in an old fam file to do this becuase it is on my local machine; has correct means and 43 lines like the one made below
subset <- read.delim("nonzero.fam", header=FALSE)
shapiro.test(subset$V6)
# W = 0.9316, p = 0.0132
```

# Step 2: Make plink format files

Load a module and run some line code

### plink filtering ###

```{bash}
module load PLINK/1.9b_4.1-x86_64

### Plink Filtered Files, include centromere

# raw phenotypes
plink -bfile /mnt/scratch/buysseso/GVCF/allsites_filtered_plinkTest --make-bed --allow-no-sex --threads 4 -pheno /mnt/scratch/buysseso/GWAS/RawLineMeans_08092022.txt --set-missing-var-ids @:# --out /mnt/scratch/buysseso/GWAS/allSNPs.PlinkFiltering_raw

# raw phenotypes, subset of only plants with some stamen loss
plink -bfile /mnt/scratch/buysseso/GWAS/allSNPs.PlinkFiltering_raw --make-bed --keep /mnt/scratch/buysseso/GWAS/lines_with_loss.txt --allow-no-sex --threads 4 --out /mnt/scratch/buysseso/GWAS/allSNPs.PlinkFiltering_raw_subset
#kept 43 lines

# asin transformed
plink -bfile /mnt/scratch/buysseso/GVCF/allsites_filtered_plinkTest --make-bed --allow-no-sex --threads 4 -pheno /mnt/scratch/buysseso/GWAS/AsinSqrtPropLineMeans_08152022.txt --set-missing-var-ids @:# --out /mnt/scratch/buysseso/GWAS/allSNPs.PlinkFiltering_Asin

# binary
plink -bfile /mnt/scratch/buysseso/GVCF/allsites_filtered_plinkTest --make-bed --allow-no-sex --threads 4 -pheno /mnt/scratch/buysseso/GWAS/BinaryPhenotype_01102023.txt --1 --set-missing-var-ids @:# --out /mnt/scratch/buysseso/GWAS/allSNPs.PlinkFiltering_Binary
# so this reads in the 0/1, but then it writes it as 1/2 which doesn't really help my issues b/c I want the fam to have 0/1 when I read it into gemma

sed 's/1$/0/g' allSNPs.PlinkFiltering_Binary.fam | sed 's/2$/1/g' > allSNPs.PlinkFiltering_Binary2.fam
mv allSNPs.PlinkFiltering_Binary2.fam allSNPs.PlinkFiltering_Binary.fam

### Plink Filtered Files, exclude centromere

# raw phenotypes
plink -bfile /mnt/scratch/buysseso/GVCF/allChrs_SNPs_NoCent --make-bed --allow-no-sex --threads 4 -pheno /mnt/scratch/buysseso/GWAS/RawLineMeans_08092022.txt --set-missing-var-ids @:# --out /mnt/scratch/buysseso/GWAS/NoCent.PlinkFiltering_raw

# raw phenotypes, subset of only plants with some stamen loss
plink -bfile /mnt/scratch/buysseso/GWAS/NoCent.PlinkFiltering_raw --make-bed --keep /mnt/scratch/buysseso/GWAS/lines_with_loss.txt --allow-no-sex --threads 4 --out /mnt/scratch/buysseso/GWAS/NoCent.PlinkFiltering_raw_subset
#kept 43 lines

# asin transformed
plink -bfile /mnt/scratch/buysseso/GVCF/allChrs_SNPs_NoCent --make-bed --allow-no-sex --threads 4 -pheno /mnt/scratch/buysseso/GWAS/AsinSqrtPropLineMeans_08152022.txt --set-missing-var-ids @:# --out /mnt/scratch/buysseso/GWAS/NoCent.PlinkFiltering_Asin

# binary
plink -bfile /mnt/scratch/buysseso/GVCF/allChrs_SNPs_NoCent --make-bed --allow-no-sex --threads 4 -pheno /mnt/scratch/buysseso/GWAS/BinaryPhenotype_01102023.txt --1 --set-missing-var-ids @:# --out /mnt/scratch/buysseso/GWAS/NoCent.PlinkFiltering_Binary

sed 's/1$/0/g' NoCent.PlinkFiltering_Binary.fam | sed 's/2$/1/g' > NoCent.PlinkFiltering_Binary2.fam
mv NoCent.PlinkFiltering_Binary2.fam NoCent.PlinkFiltering_Binary.fam

```

All log files confirm there are 61 individuals with phenotypes after running the code lines unless noted.

# Step 3: Make relatedness matrix

### Plink Filtering ###
```{bash}
cd /mnt/scratch/buysseso/GWAS

### with centromere ###
# 1858694 of 1858706 SNPs analyzed

## centered
# raw
~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_raw -gk 1 -notsnp -miss 1.0 -o RelMat/All/allSNPs.PlinkFiltering_raw
# subset
~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_raw_subset -gk 1 -notsnp -miss 1.0 -o RelMat/All/allSNPs.PlinkFiltering_raw_subset

# Asin
~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_Asin -gk 1 -notsnp -miss 1.0 -o RelMat/All/allSNPs.PlinkFiltering_Asin

# Binary
~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_Binary -gk 1 -notsnp -miss 1.0 -o RelMat/All/allSNPs.PlinkFiltering_Binary

## standardized
# raw
~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_raw -gk 2 -notsnp -miss 1.0 -o RelMat/All/allSNPs.PlinkFiltering_raw


### without centromere ###
# 1507319/1507328 SNPs analyzed

## centered - only did centered here
# raw
~/Apps/gemma-0.98.4-linux-static -bfile NoCent.PlinkFiltering_raw -gk 1 -notsnp -miss 1.0 -o RelMat/NoCent/NoCent.PlinkFiltering_raw

# subset raw
~/Apps/gemma-0.98.4-linux-static -bfile NoCent.PlinkFiltering_raw_subset -gk 1 -notsnp -miss 1.0 -o RelMat/NoCent/NoCent.PlinkFiltering_raw_subset

# Asin
~/Apps/gemma-0.98.4-linux-static -bfile NoCent.PlinkFiltering_Asin -gk 1 -notsnp -miss 1.0 -o RelMat/NoCent/NoCent.PlinkFiltering_Asin

# Binary
~/Apps/gemma-0.98.4-linux-static -bfile NoCent.PlinkFiltering_Binary -gk 1 -notsnp -miss 1.0 -o RelMat/NoCent/NoCent.PlinkFiltering_Binary

```

# Step 4: Run GWAS

### Plink Filtering ###

Updated 1/24/2023 so that all files are using -lmm 4 to run all 3 ways of calculating the p value. The beta and se are included when using the wald test.

#### with the centromere included ####
```{bash}
# start in correct location
cd /mnt/scratch/buysseso/GWAS

# Raw phenotypes, centered relmat
~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_raw -k output/RelMat/All/allSNPs.PlinkFiltering_raw.cXX.txt -lmm 4 -notsnp -miss 1.0 -o GWAS/All/allSNPs.PlinkFiltering_raw.c
# pve estimate = 0.778955, se(pve) = 0.101311

## Raw phenotypes, centered relmat, but do all the p value tests just to see
#~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_raw -k output/RelMat/All/allSNPs.PlinkFiltering_raw.cXX.txt #-lmm 4 -notsnp -miss 1.0 -o GWAS/All/allSNPs.PlinkFiltering_raw.c_testing
## pve estimate = 0.778955, se(pve) = 0.101311

# Subset of raw phenotypes, centered relmat
~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_raw_subset -k output/RelMat/All/allSNPs.PlinkFiltering_raw_subset.cXX.txt -lmm 4 -notsnp -miss 1.0 -o GWAS/All/allSNPs.PlinkFiltering_raw_subset.c
# pve estimate = 0.791614, se(pve) = 0.115285

# Asin phenotypes, centered relmat
~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_Asin -k output/RelMat/All/allSNPs.PlinkFiltering_Asin.cXX.txt -lmm 4 -notsnp -miss 1.0 -o GWAS/All/allSNPs.PlinkFiltering_Asin.c
# pve estimate = 0.7064, se(pve) = 0.123102

# Binary phenotypes, centered relmat
~/Apps/gemma-0.98.4-linux-static -bfile allSNPs.PlinkFiltering_Binary -k output/RelMat/All/allSNPs.PlinkFiltering_Binary.cXX.txt -lmm 4 -notsnp -miss 1.0 -o GWAS/All/allSNPs.PlinkFiltering_Binary.c
# pve = 0.29391 se(pve) = 0.160083
```

###### does the test matter? ######
```{r}
result_table <- read.delim("~/GemmaOutput_2022/allSNPs.PlinkFiltering_raw.c_testing.assoc.txt")

#plot(x = result_table$p_wald, y = result_table$p_lrt)

cor(result_table$p_wald, result_table$p_lrt, method = "pearson")
# correlation is 0.9984886

```

#### without the centromere ####

Updated 1/24/2023 to use -lmm 4 and run all of the p value tests

```{bash}
# start in correct location
cd /mnt/scratch/buysseso/GWAS

# Raw phenotypes, centered relmat
~/Apps/gemma-0.98.4-linux-static -bfile NoCent.PlinkFiltering_raw -k output/RelMat/NoCent/NoCent.PlinkFiltering_raw.cXX.txt -lmm 4 -notsnp -miss 1.0 -o GWAS/NoCent/NoCent.PlinkFiltering_raw.c
# pve estimate = 0.761723, se(pve) = 0.0996641

# subset raw phenotypes, centered relmat
~/Apps/gemma-0.98.4-linux-static -bfile NoCent.PlinkFiltering_raw_subset -k output/RelMat/NoCent/NoCent.PlinkFiltering_raw_subset.cXX.txt -lmm 4 -notsnp -miss 1.0 -o GWAS/NoCent/NoCent.PlinkFiltering_raw_subset.c
# pve estimate = 0.774126, se(pve) = 0.11436

# Asin phenotypes, centered relmat
~/Apps/gemma-0.98.4-linux-static -bfile NoCent.PlinkFiltering_Asin -k output/RelMat/NoCent/NoCent.PlinkFiltering_Asin.cXX.txt -lmm 4 -notsnp -miss 1.0 -o GWAS/NoCent/NoCent.PlinkFiltering_Asin.c
# pve estimate = 0.689438, se(pve) = 0.120383

# Binary phenotypes, centered relmat
~/Apps/gemma-0.98.4-linux-static -bfile NoCent.PlinkFiltering_Binary -k output/RelMat/NoCent/NoCent.PlinkFiltering_Binary.cXX.txt -lmm 4 -notsnp -miss 1.0 -o GWAS/NoCent/NoCent.PlinkFiltering_Binary.c
# pve estimate = 0.291117, se(pve) = 0.156126
```

Trend is that percent variance explained (pve) is slightly lower for all of the NoCent files with short stamen as the phenotypes (continuous or binary). no cent explains slightly more but the change is SUPER small.\

# Step 5: Pull out list of top hits #

```{r top_hits}
# read in packages
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(qqman))

# list of all the files I am interested in
files <- c("NoCent.PlinkFiltering_Binary.c", "NoCent.PlinkFiltering_raw.c",  "NoCent.PlinkFiltering_Asin.c", "allSNPs.PlinkFiltering_Asin.c", "allSNPs.PlinkFiltering_raw.c", "allSNPs.PlinkFiltering_Binary.c", "allSNPs.PlinkFiltering_raw_subset.c", "NoCent.PlinkFiltering_raw_subset.c")

```

## pull out all hits above fdr
The code chunk ends by writing out a csv with all the hits above fdr. 0.10

```{r}
##### pull out all hits above fdr 0.10#####

# step one: decide fdr level to use
## make a dataframe that only has the fdr adjusted p values. do this in a loop for space reasons I think? wait can I do that?
#fdr_pvals <- vector("list", length(files))
#for (name in c(1:length(files))){
#  identifier <- files[name]
#  filename = paste0("~/GemmaOutput_2022/", identifier, ".assoc.txt")
#  results <- read.delim(file= filename, header = T, stringsAsFactors = F)
#  fdr_tmp <- p.adjust(p= results$p_wald, method = "fdr")
#  fdr_pvals[[name]] <- fdr_tmp
#} 
#names(fdr_pvals) <- files
#
## save this as the end of the day on 4/12 pick it up again later with trying to find what threshhold to actually set
#save(fdr_pvals, file = "~/R_script/GWAS_fdradjusted_pvals.ROBJ")


# load in the file!
load(file = "~/R_script/GWAS_fdradjusted_pvals.ROBJ")

# because this is the fdr adjusted value, I do still need to do the -log of them if I want low p values at the top, but I also think if I want a 0.10 cutoff, I can just print all values below that 

sum(fdr_pvals[[1]] < 0.10)
#2382 - no cent - binary
sum(fdr_pvals[[2]] < 0.10)
#60 - no cent - raw
sum(fdr_pvals[[3]] < 0.10)
# 11 - no cent - asin
sum(fdr_pvals[[4]] < 0.10)
# 11003 - no cent - elev
sum(fdr_pvals[[5]] < 0.10)
#15 - allSNPS - asin
sum(fdr_pvals[[6]] < 0.10)
# 50 - allSNPs - raw
sum(fdr_pvals[[7]] < 0.10)
# 8604 - allSNPs - elev
sum(fdr_pvals[[8]] < 0.10)
# 3395 - allSNPs - binary
sum(fdr_pvals[[9]] < 0.10)
#15 - allSNPs - subset
sum(fdr_pvals[[10]] < 0.10)
# 13 - no cent - subset

# what about 0.15 for the ones with fewer snps at this level?
sum(fdr_pvals[[3]] < 0.15)
# 22 - no cent - asin
sum(fdr_pvals[[10]] < 0.15)
# 18 - no cent - subset

# step two: pull out all snps above that level (p = 0.10)

#for each gwas file, I want to subset out based on fdr_vals[[i]] < 0.10
#test it first
nocent_bin <- read.delim(file = paste0("~/GemmaOutput_2022/", files[1], ".assoc.txt"))

# check that lengths match
length(nocent_bin$ps)
length(fdr_pvals[[1]])

# pull them out
nocent_bin_top <- nocent_bin[fdr_pvals[[1]] < 0.10, ]
# check expected output lengths match 
sum(fdr_pvals[[1]] < 0.10)
length(nocent_bin_top$ps)

# step three: do for each GWAS
# loop outline
top_hits_fdr <- list()
for (i in c(1:length(files))){
  identifier <- files[i]
  filename = paste0("~/GemmaOutput_2022/", identifier, ".assoc.txt")
  results <- read.delim(file= filename, header = T, stringsAsFactors = F)
  top_hits_fdr[[i]] <- results[fdr_pvals[[i]] < 0.10, c("chr", "rs", "ps", "beta", "se", "p_wald")]
  # rename the columns
  colnames(top_hits_fdr[[i]]) <- c("chr", "rs", "ps", paste0("beta_",files[i]), paste0("se_",files[i]), paste0("p_",files[i]))
  rm(results)
} 

# check that all the lengths are what i was expecting - did this manually with my environment

# step four: merge into single dataset
top_hits_fdr_all <- Reduce(function(dtf1, dtf2) merge(dtf1, dtf2, by = c("chr", "rs", "ps"), all = TRUE),
        top_hits_fdr)
colnames(top_hits_fdr_all) <- c("chr", "rs", "ps", "beta_binary_nc", "se_binary_nc", "p_binary_nc", "beta_raw_nc", "se_raw_nc", "p_raw_nc", "beta_asin_nc", "se_asin_nc", "p_asin_nc", "beta_asin_all", "se_asin_all", "p_asin_all", "beta_raw_all", "se_raw_all", "p_raw_all", "beta_binary_all", "se_binary_all", "p_binary_all", "beta_subset_all", "se_subset_all", "p_subset_all", "beta_subset_nc", "se_subset_nc", "p_subset_nc")

# write this out
write.csv(top_hits_fdr_all, "~/GemmaOutput_2022/Top_hits_fdr_wald_Apr2023.csv", row.names = FALSE)

```

This next section pulls out all the hits above fdr 0.05 to use for genome browsing. It writes out a .cvs just like the previous section.

```{r}
##### pull out all hits above fdr 0.05 #####

# load in the file!
load(file = "~/R_script/GWAS_fdradjusted_pvals.ROBJ")

# because this is the fdr adjusted value, I do still need to do the -log of them if I want low p values at the top, but I also think if I want a 0.10 cutoff, I can just print all values below that 

sum(fdr_pvals[[1]] < 0.05)
#1004 - no cent - binary
sum(fdr_pvals[[2]] < 0.05)
#2 - no cent - raw
sum(fdr_pvals[[3]] < 0.05)
# 1 - no cent - asin
sum(fdr_pvals[[4]] < 0.05)
# 7302 - no cent - elev
sum(fdr_pvals[[5]] < 0.05)
#2 - allSNPS - asin
sum(fdr_pvals[[6]] < 0.05)
#2 - allSNPs - raw
sum(fdr_pvals[[7]] < 0.05)
# 5108 - allSNPs - elev
sum(fdr_pvals[[8]] < 0.05)
# 1707 - allSNPs - binary
sum(fdr_pvals[[9]] < 0.05)
#3 - allSNPs - subset
sum(fdr_pvals[[10]] < 0.05)
#7 - no cent - subset

# step two: pull out all snps above 0.05

# the indexing should be the same, so I should be able to use the indexing from fdr_pvals
#so for each gwas file, I want to subset out based on fdr_vals[[i]] < 0.05

# loop outline
top_hits_fdr <- list()
for (i in c(1:length(files))){
  identifier <- files[i]
  filename = paste0("~/GemmaOutput_2022/", identifier, ".assoc.txt")
  results <- read.delim(file= filename, header = T, stringsAsFactors = F)
  top_hits_fdr[[i]] <- results[fdr_pvals[[i]] < 0.05, c("chr", "rs", "ps", "beta", "se", "p_wald")]
  # rename the columns
  colnames(top_hits_fdr[[i]]) <- c("chr", "rs", "ps", paste0("beta_",files[i]), paste0("se_",files[i]), paste0("p_",files[i]))
  rm(results)
} 

# check that all the lengths are what i was expecting - did this manually with my environment

# step four: merge into single dataset
top_hits_fdr_all <- Reduce(function(dtf1, dtf2) merge(dtf1, dtf2, by = c("chr", "rs", "ps"), all = TRUE),
        top_hits_fdr)
colnames(top_hits_fdr_all) <- c("chr", "rs", "ps", "beta_binary_nc", "se_binary_nc", "p_binary_nc", "beta_raw_nc", "se_raw_nc", "p_raw_nc", "beta_asin_nc", "se_asin_nc", "p_asin_nc", "beta_asin_all", "se_asin_all", "p_asin_all", "beta_raw_all", "se_raw_all", "p_raw_all", "beta_binary_all", "se_binary_all", "p_binary_all", "beta_subset_all", "se_subset_all", "p_subset_all", "beta_subset_nc", "se_subset_nc", "p_subset_nc")

# write this out
write.csv(top_hits_fdr_all, "~/GemmaOutput_2022/Top_hits_fdr_wald_Apr2023_05.csv", row.names = FALSE)

```

# Step 6: Window Analysis
this code reads in the April 2023 file and writes the output to a list of lists rather than just to the console.

```{r}
library(praise)
##### do it time 3 #####
# read in top hits file
top_hits_fdr_all <- read.csv("~/GemmaOutput_2022/Top_hits_fdr_wald_Apr2023.csv")

#make a 1000bp window centered on the SNP
top_hits_fdr_all$min <- top_hits_fdr_all$ps - 500
top_hits_fdr_all$max <- top_hits_fdr_all$ps + 500

### things that happen to all chromosomes at once ###

# NOTE: There was an elevation GWAS that was later removed from the analysis, but remnants of removing it are present here.
th_fdr_noelev <- top_hits_fdr_all[, grep("elev", colnames(top_hits_fdr_all), value = TRUE, invert = TRUE)]

# to solve the problem of making sure the overlap is between two GWAS types, I should also only look at either all or NoCent at once
# using the 'inverse of all' code so the first three columns are also kept
th_noelev_nocent <- top_hits_fdr_all[, grep("all", colnames(th_fdr_noelev), value = TRUE, invert = TRUE)]
# using the 'inverse of nocent' code so the first three columns are also kept
th_noelev_all <- top_hits_fdr_all[, grep("nc", colnames(th_fdr_noelev), value = TRUE, invert = TRUE)]

# count NAs, and  keep rows with fewer than 12 NAs (3 columns should have values for all rows)
th_noelev_nocent <- th_noelev_nocent[rowSums(is.na(th_noelev_nocent)) < 12 , ] 
# sample size went way down!
th_noelev_all <- th_noelev_all[rowSums(is.na(th_noelev_all)) < 12 , ] 
# sample size went way down! but is larger than no cent.

#### Functions ####

# nested loops that give me an output that is a list of dataframes with at least 2 overlapping SNPs in the window

id_snps <- function(input){
  output <- list()
  len <- length(input$ps) # to this point works
  # loop that makes a list of all SNPs in the window
  for (i in c(1:len)){
    tmp_list <- c(input$min[i]:input$max[i])
    tmp_df <- data.frame()
    # loop that checks if snps in the dataframe are in the list of all SNPs in the window
    for (j in c(1:len)){
     if (input$ps[j] %in% tmp_list) {
        tmp_df <- rbind(tmp_df, input[j, ])}
    }
    # add new dataframe to a list of dataframes to be in the output
    output <- append(output, list(tmp_df))
  }
  return(output)
}

#testing123 <- id_snps(hits_fdr_chr1)
#identical(testing123, chr1_overlap_nc)
## celebrate!
#praise()

nc_p_cols <- c("p_binary_nc", "p_raw_nc", "p_asin_nc", "p_subset_nc")
all_p_cols <- c("p_binary_all", "p_raw_all", "p_asin_all", "p_subset_all")


gwas_overlap <- function(input, keep_cols){
  cols_with_values <- c()
  for(d in c(1:length(input))){
  cols_with_values[d] <- sum(colSums(is.na(input[[d]][,keep_cols])) < length(input[[d]][ ,1]))
  }
  # then write out the dataframes from the initial list
  output <- input[c(cols_with_values > 1)]
  return(output)
}

##testing further below, it seems to work!
praise()
```

#### Chromosome 1

```{r chr1, eval = FALSE}
#### chr 1 ####
##### no cent #####
# only keep the p value columns
hits_fdr_chr1 <- th_noelev_nocent[(th_noelev_nocent$chr == 1), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_nocent), value = TRUE), "min", "max")]

# run that function!
chr1_overlap_nc <- id_snps(hits_fdr_chr1)

# output makes more sense when ran in the console

length(unique(chr1_overlap_nc)) # only 115 are unique; 232 unique when keeping tmp_df with only one row (i.e., one SNP)


# don't expect this to keep any
OverlapHits_chr1_nc <- gwas_overlap(chr1_overlap_nc, nc_p_cols)
# and it didn't

# manually scrolling through, all of the overlap just with nocent is only within a single gwas type... what changed? some hits must not have made the cutoff.

#try it on all instead of NC
##### all  #####
# only keep the p value columns
hits_fdr_chr1_a <- th_noelev_all[(th_noelev_all$chr == 1), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_all), value = TRUE), "min", "max")]

# fancy function I wrote
chr1_overlap_all <- id_snps(hits_fdr_chr1_a)

# This has 279 entries
length(unique(chr1_overlap_all)) # only 133 are unique with 2+ SNPs, 285 are unique with at least one SNP
# manually checked the places where I had overlap with the top 50, and what seems to have changed in the 2243xxxx region is that those SNPS didn't make the cutoff for the subset analysis, so they are not included and my overlap has disappeared.

OverlapHits_chr1_all <- gwas_overlap(chr1_overlap_all, all_p_cols)

# start shared snps list
shared_snps <- unique(c(OverlapHits_chr1_all[[1]]$rs))
```

##### some more testing #####

```{r, eval = FALSE}
### test to make sure the loop to only identify dataframes with p values from at least 2 GWAS types works on different types of dataframes. ###
# data frame with only 1 value per row, but values are in 2 different columns
df1 <- data.frame("p_binary_nc" = c(NA, 0.1, 0.1, 0.1), "p_raw_nc" = c(NA, NA, NA, NA), "p_asin_nc"= c(NA, NA, NA, NA), "p_subset_nc"= c(0.1, NA, NA, NA))
# df with 1 value per row, but each value is in a different column
df2 <- data.frame("p_binary_nc" = c(0.1, NA, NA, NA), "p_raw_nc" = c(NA, 0.1, NA, NA), "p_asin_nc"= c(NA, NA, 0.1, NA), "p_subset_nc"= c(NA, NA, NA, 0.1))
# df that is all NAs
df3 <- data.frame("p_binary_nc" = c(NA, NA, NA, NA), "p_raw_nc" = c(NA, NA, NA, NA), "p_asin_nc"= c(NA, NA, NA, NA), "p_subset_nc"= c(NA, NA, NA, NA))
# df with values in the same row of multiple columns
df4 <- data.frame("p_binary_nc" = c(0.1, NA, NA, NA), "p_raw_nc" = c(0.1, NA, NA, NA), "p_asin_nc"= c(NA, NA, NA, NA), "p_subset_nc"= c(NA, NA, NA, NA))
# df with values in the same row of multiple columns. and values in two rows
df5 <- data.frame("p_binary_nc" = c(0.1, NA, NA, NA), "p_raw_nc" = c(0.1, NA, NA, NA), "p_asin_nc"= c(NA, NA, 0.1, NA), "p_subset_nc"= c(NA, NA, NA, 0.1))
# all values everywhere, and a different length
df6 <- data.frame("p_binary_nc" = c(0.1, 0.1, 0.1), "p_raw_nc" = c(0.1, 0.1, 0.1), "p_asin_nc"= c(0.1, 0.1, 0.1), "p_subset_nc"= c(0.1, 0.1, 0.1))
# df1 but different length
df7 <- data.frame("p_binary_nc" = c(NA, 0.1, 0.1, 0.1, 0.1), "p_raw_nc" = c(NA, NA, NA, NA, NA), "p_asin_nc"= c(NA, NA, NA, NA, NA), "p_subset_nc"= c(0.1, NA, NA, NA, NA))
# all values in one column
df8 <- data.frame("p_binary_nc" = c(0.1, 0.1, 0.1, 0.1, 0.1), "p_raw_nc" = c(NA, NA, NA, NA, NA), "p_asin_nc"= c(NA, NA, NA, NA, NA), "p_subset_nc"= c(NA, NA, NA, NA, NA))
tmp_dfs <- list(df1, df2, df3, df4, df5, df6, df7, df8)

# I want my code to keep any instance where there are values in multiple columns, so that would be all but df3 and df8

# loop!
Cols_with_values <- c()
for(d in c(1:length(tmp_dfs))){
  Cols_with_values[d] <- sum(colSums(is.na(tmp_dfs[[d]][,c("p_binary_nc", "p_raw_nc", "p_asin_nc", "p_subset_nc")])) < length(tmp_dfs[[d]]$p_raw_nc))
}

# okay this works. the cols_wht_values list value is an integer that represents the number of columns with at least one value.

# I then want to subset tmp_dfs based on this and only keep the entries where the corresponding Cols_with_values entry is greater than 1
tmp_dfs_2 <- tmp_dfs[c(Cols_with_values > 1)]

# now test the function
gwas_overlap(tmp_dfs, nc_p_cols)

# empty output which is what I was expecting, but I need to return early if I want to check the inner workings of the function.
# BUT returning early gives me a list of zeros which is not what I want.
# needed to fix how I was indexing the length of the columns, it now works by using [] and a number instead of $"name"

```

#### Chromosome 2

```{r chr2, eval = FALSE}
##### no cent #####
# only keep the p value columns
hits_fdr_chr2 <- th_noelev_nocent[(th_noelev_nocent$chr == 2), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_nocent), value = TRUE), "min", "max")]

# run that function!
chr2_overlap_nc <- id_snps(hits_fdr_chr2)
#271 elements
length(unique(chr2_overlap_nc)) # 103 unique, 210 when including windows with only 1 SNP

# check for overlap between gwas types
OverlapHits_chr2_nc <- gwas_overlap(chr2_overlap_nc, nc_p_cols)
# empty list :(

##### all  #####
# only keep the p value columns
hits_fdr_chr2_a <- th_noelev_all[(th_noelev_all$chr == 2), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_all), value = TRUE), "min", "max")]

# fancy function I wrote
chr2_overlap_all <- id_snps(hits_fdr_chr2_a) # 306 elements
length(unique(chr2_overlap_all)) # 118 are unique, 244 are unique when including windows with only 1 SNP
# fancy function 2
OverlapHits_chr2_all <- gwas_overlap(chr2_overlap_all, all_p_cols)
# empty list
```

No overlap when cutoff is fdr 0.10. This remains when looking at windows with only 1 SNP.

#### Chromosome 3

```{r chr3, eval = FALSE}
##### no cent #####
# only keep the p value columns
hits_fdr_chr3 <- th_noelev_nocent[(th_noelev_nocent$chr == 3), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_nocent), value = TRUE), "min", "max")]

# run that function!
chr3_overlap_nc <- id_snps(hits_fdr_chr3)
#628 elements, 826 when keeping one SNP windows
length(unique(chr3_overlap_nc)) # 272 unique, 470 unique when keeping one SNP windows

# check for overlap between gwas types
OverlapHits_chr3_nc <- gwas_overlap(chr3_overlap_nc, nc_p_cols)
# keeps 3 when keeping windows with only one SNP (none if require 2 SNPs)

##### all  #####
# only keep the p value columns
hits_fdr_chr3_a <- th_noelev_all[(th_noelev_all$chr == 3), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_all), value = TRUE), "min", "max")]

# fancy function I wrote
chr3_overlap_all <- id_snps(hits_fdr_chr3_a) # 758 elements
length(unique(chr3_overlap_all)) # 328 are unique, 581 unique when keeping 1 SNP windows
# fancy function 2
OverlapHits_chr3_all <- gwas_overlap(chr3_overlap_all, all_p_cols)
# list of 3, the same as the ones that show up with nc

# add to shared snps list
shared_snps <- append(shared_snps, unique(c(OverlapHits_chr3_all[[1]]$rs, OverlapHits_chr3_all[[2]]$rs, OverlapHits_chr3_all[[3]]$rs)))
shared_snps
```

3 SNPs overlap with fdr 0.10 cutoff. These are the same for both nc and all

#### Chromosome 4

```{r chr4, eval = FALSE}
##### no cent #####
# only keep the p value columns
hits_fdr_chr4 <- th_noelev_nocent[(th_noelev_nocent$chr == 4), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_nocent), value = TRUE), "min", "max")]

# run that function!
chr4_overlap_nc <- id_snps(hits_fdr_chr4)
#only 36! 64 when including 1 SNP windows
length(unique(chr4_overlap_nc)) # 17 unique, 45 with 1 SNP windows

# check for overlap between gwas types
OverlapHits_chr4_nc <- gwas_overlap(chr4_overlap_nc, nc_p_cols)
# empty list :(

##### all  #####
# only keep the p value columns
hits_fdr_chr4_a <- th_noelev_all[(th_noelev_all$chr == 4), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_all), value = TRUE), "min", "max")]

# fancy function I wrote
chr4_overlap_all <- id_snps(hits_fdr_chr4_a) # 43 elements (82 with 1 SNP windows)
length(unique(chr4_overlap_all)) # 16 are unique (55 unique with 1 SNp windows)
# fancy function 2
OverlapHits_chr4_all <- gwas_overlap(chr4_overlap_all, all_p_cols)
# empty list
```

No overlap when cutoff is fdr 0.10 even when including 1 SNP windows.

#### Chromosome 5

```{r chr5, eval = FALSE}
##### no cent #####
# only keep the p value columns
hits_fdr_chr5 <- th_noelev_nocent[(th_noelev_nocent$chr == 5), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_nocent), value = TRUE), "min", "max")]

# run that function!
chr5_overlap_nc <- id_snps(hits_fdr_chr5)
#624 elements! (840 with 1 SNP windows)
length(unique(chr5_overlap_nc)) 
# 278 unique that have 2+ SNPs - wow that cut down a lot
# 494 unique without the filtering for 2+ SNPs. so does this mean there are only 494 unique windows out of 840? I guess I'm not entirely sure what this means right now.

# check for overlap between gwas types
OverlapHits_chr5_nc <- gwas_overlap(chr5_overlap_nc, nc_p_cols)
# list of 8 that have 2+ SNPs!
# list of 11 that have at least 1 SNP - includes the 8 from before plus 3 earlier in the chromosome

##### all  #####
# only keep the p value columns
hits_fdr_chr5_a <- th_noelev_all[(th_noelev_all$chr == 5), c("chr", "rs", "ps", grep("p_", colnames(th_noelev_all), value = TRUE), "min", "max")]

# fancy function I wrote
chr5_overlap_all <- id_snps(hits_fdr_chr5_a) #  1191 elements - something going on in this centromere (1505 with 1 SNP windows)
length(unique(chr5_overlap_all)) # 602 are unique ( 916 unique with 1 SNP windows)
# fancy function 2
OverlapHits_chr5_all <- gwas_overlap(chr5_overlap_all, all_p_cols)
# list of 11!
# list of 13 when including 1 SNP windows. which means all only added 2 new windows but nc added 3. hmm.

# add to list of all the SNPs overlapping at all here to highlight in a GWAS figure.
shared_snps <- append(shared_snps, unique(c(OverlapHits_chr5_all[[1]]$rs, OverlapHits_chr5_all[[2]]$rs, OverlapHits_chr5_all[[3]]$rs, OverlapHits_chr5_all[[4]]$rs, OverlapHits_chr5_all[[5]]$rs, OverlapHits_chr5_all[[6]]$rs, OverlapHits_chr5_all[[7]]$rs, OverlapHits_chr5_all[[8]]$rs, OverlapHits_chr5_all[[9]]$rs, OverlapHits_chr5_all[[10]]$rs, OverlapHits_chr5_all[[11]]$rs, OverlapHits_chr5_all[[12]]$rs, OverlapHits_chr5_all[[13]]$rs, OverlapHits_chr5_nc[[1]]$rs, OverlapHits_chr5_nc[[2]]$rs, OverlapHits_chr5_nc[[3]]$rs, OverlapHits_chr5_nc[[4]]$rs, OverlapHits_chr5_nc[[5]]$rs, OverlapHits_chr5_nc[[6]]$rs, OverlapHits_chr5_nc[[7]]$rs, OverlapHits_chr5_nc[[8]]$rs, OverlapHits_chr5_nc[[9]]$rs, OverlapHits_chr5_nc[[10]]$rs, OverlapHits_chr5_nc[[11]]$rs)))
shared_snps
```

1/25/2024: Important note!
The shared_snps list is only for a comparison between the 4 short stamen number gwas types. This does not take into account the elevation hits at all. The shared_snps list of snps are the only ones that are highlighted on the manhattan plots right now. because there are so many snps identified when I added elevation in to the mix, I need to think about how I want to highlight them and genome browse them.


### Join lists together
take all the overlap lists I just made, and merge them together into one for no cent and one for all
```{r}
all_1 <- bind_rows(OverlapHits_chr1_all, .id = "window")
# one window does not have elevation
all_2 <- bind_rows(OverlapHits_chr2_all, .id = "window")
# all windows include an elevation hit
all_3 <- bind_rows(OverlapHits_chr3_all, .id = "window")
all_4 <- bind_rows(OverlapHits_chr4_all, .id = "window")
# all windows include an elevation hit
all_5 <- bind_rows(OverlapHits_chr5_all, .id = "window")
# not all windows include an elevation hit, but most do

# add '.id = "window"' if I want to know which window each row came from.

overlap_all <- rbind(all_1, all_2, all_3, all_4, all_5)
length(unique(overlap_all$rs))
# hmm okay so this dataframe has 2386 observations but only 282 of them are actually unique rows and the rest are duplicates that are snps that show up in multiple windows....
overlap_all2 <- distinct(overlap_all[2:11])

write.csv(overlap_all2, file = "data/AllChrs_Overlap_20240125.csv", row.names = FALSE)
```

```{r}
nc_1 <- bind_rows(OverlapHits_chr1_nc)
nc_2 <- bind_rows(OverlapHits_chr2_nc)
nc_3 <- bind_rows(OverlapHits_chr3_nc)
nc_4 <- bind_rows(OverlapHits_chr4_nc)
nc_5 <- bind_rows(OverlapHits_chr5_nc)

overlap_nc <- rbind(nc_1, nc_2, nc_3, nc_4, nc_5)
length(unique(overlap_nc$rs))
# hmm okay so this dataframe has 2806 observations but only 289 of them are actually unique rows and the rest are duplicates that are snps that show up in multiple windows....
overlap_nc2 <- distinct(overlap_nc)

write.csv(overlap_nc2, file = "data/NoCent_Overlap_20240125.csv", row.names = FALSE)

```

# Step 7: Effect Sizes #
```{r}
library(dplyr)

files <- c("NoCent.PlinkFiltering_Binary.c", "NoCent.PlinkFiltering_raw.c",  "NoCent.PlinkFiltering_Asin.c", "allSNPs.PlinkFiltering_Asin.c", "allSNPs.PlinkFiltering_raw.c", "allSNPs.PlinkFiltering_Binary.c", "allSNPs.PlinkFiltering_raw_subset.c", "NoCent.PlinkFiltering_raw_subset.c")

p_effect_cor <- function(identifier){
  ##### Set filenames and read in file #####
  
  filename = paste0("~/GemmaOutput_2022/", identifier, ".assoc.txt")
  
  results <- read.delim(file= filename, header = T, stringsAsFactors = F)
  
  #use abs() because we want large effect vs small effect, the direction is not important.
  return(cor(abs(results$beta), results$p_wald, method = "pearson"))
  
}

#test it out, do I get a list or a list of lists?

p_effect_cor("NoCent.PlinkFiltering_Binary.c")
tmp <- p_effect_cor("NoCent.PlinkFiltering_Binary.c")
#why does it print out the value instead of just saving it to the object?
tmp <- sapply(files, p_effect_cor, simplify = TRUE, USE.NAMES = TRUE)
# this output is actually what I want, it is a named vectors if I use simply = TRUE
tmp

#could plot it, but that will be a lot of points and will take a lot of computer power that I don't want to use right now.
NoCent_raw <- read.delim(file = "~/GemmaOutput_2022/NoCent.PlinkFiltering_raw.c.assoc.txt", header = T, stringsAsFactors = F)

reg <- lm(abs(beta) ~ p_wald, data = NoCent_raw)
summary(reg)
# r2 is decently high
# slope = -1.470e-01
# intercept = 1.344e-01

ggplot(data = NoCent_raw, aes(x = p_wald, y = abs(beta)))+
  geom_point(alpha = 0.1)+
  theme_classic()
  # don't want the line geom_abline(intercept=max(abs(NoCent_raw$beta)), slope=-0.8411929, linetype="solid", color ="red")

```
